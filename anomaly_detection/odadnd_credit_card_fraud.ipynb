{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "odadnd_credit_card_fraud.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpIzfDd29r7X",
        "colab_type": "text"
      },
      "source": [
        "# Credit Card Fraud Detection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y50dwIWg9svk",
        "colab_type": "text"
      },
      "source": [
        "## About\n",
        "\n",
        "Credit card fraud detection is a real world problem that is plaguing the nations. It is an anomaly detection problem due to the Poisson distributed positive cases. Fraud doesn't happen every day, but when it does happen, we want to capture it and predict, given the types of patterns that we can detect, which accounts will likely experience an instance of fraudulent activity.\n",
        "\n",
        "Being able to work with fraud detection gives us insight into working with all sorts of anomaly detection type problems in the feature, even outside this particular domain."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2cZ-3Ok9uOR",
        "colab_type": "text"
      },
      "source": [
        "## The Dataset\n",
        "\n",
        "The dataset was retrieved from data world, which retrieved it from a Kaggle competitition. It's a flat datset and not necessarily considered big data, however, it will serve its purpose here. \n",
        "\n",
        "The attributes for the dataset, for the most part, were stripped so we don't really have a human readable understanding of what the attributes mean, but from what I can tell, the values for each of these anonymized attributes are normalized values.\n",
        "\n",
        "Our target is a boolean, indicating whether or not the account has experienced fraudulent activity or not.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EfJWGiKZkUIF",
        "colab_type": "text"
      },
      "source": [
        "## Download External Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fuw0XkOykbGQ",
        "colab_type": "code",
        "outputId": "649b5014-f42d-49fa-c18b-6c1000026c5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        }
      },
      "source": [
        "!pip install pyod\n",
        "!pip install imbalance-learn"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyod\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f9/40/2bffcde2edbbea4e8ae50a868684fd285d746401bd8051732d3a6d6111c4/pyod-0.7.5.tar.gz (86kB)\n",
            "\r\u001b[K     |███▉                            | 10kB 26.5MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 20kB 4.0MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 30kB 5.8MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 40kB 7.5MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 51kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 61kB 5.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 71kB 6.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 81kB 7.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 92kB 4.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from pyod) (0.14.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from pyod) (3.1.1)\n",
            "Requirement already satisfied: numpy>=1.13 in /usr/local/lib/python3.6/dist-packages (from pyod) (1.17.4)\n",
            "Requirement already satisfied: numba>=0.35 in /usr/local/lib/python3.6/dist-packages (from pyod) (0.40.1)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from pyod) (1.3.2)\n",
            "Requirement already satisfied: scikit_learn>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from pyod) (0.21.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from pyod) (1.12.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->pyod) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->pyod) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->pyod) (2.6.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->pyod) (2.4.5)\n",
            "Requirement already satisfied: llvmlite>=0.25.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.35->pyod) (0.30.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib->pyod) (41.6.0)\n",
            "Building wheels for collected packages: pyod\n",
            "  Building wheel for pyod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyod: filename=pyod-0.7.5-cp36-none-any.whl size=96597 sha256=ab14b4a9d755c5ef417857b58523d12b3580b3fa466ac7651785ffbb3c309a3c\n",
            "  Stored in directory: /root/.cache/pip/wheels/35/bc/f4/2cef321eac851ba02f533e3921b296bb4ce4998c8a4c9a8d6e\n",
            "Successfully built pyod\n",
            "Installing collected packages: pyod\n",
            "Successfully installed pyod-0.7.5\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement imbalance-learn (from versions: none)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for imbalance-learn\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G76WeA6e_TcL",
        "colab_type": "text"
      },
      "source": [
        "## Load Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXsfd3ow_Vuz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt \n",
        "import seaborn as sns\n",
        "from collections import Counter\n",
        "from inspect import signature\n",
        "%matplotlib inline\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pprint\n",
        "pp = pprint.PrettyPrinter(indent=4)\n",
        "\n",
        "from google.colab import drive\n",
        "import pandas_profiling\n",
        "from timeit import default_timer\n",
        "from sklearn.metrics import (precision_score, confusion_matrix, recall_score, accuracy_score, \n",
        "                             balanced_accuracy_score,roc_auc_score, classification_report, confusion_matrix, \n",
        "                             r2_score, f1_score, roc_curve, precision_recall_curve, average_precision_score)\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "from sklearn.linear_model import SGDClassifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1j1p9T_nxNo",
        "colab_type": "text"
      },
      "source": [
        "## Constants"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Mnb8BeknzQt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DRIVENAME = \"/content/drive/\"\n",
        "FILENAME = \"/content/drive/My Drive/problem_set_challenges_for_job_postings/scaled_and_processed_cc.csv\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WE7Y6nIOcHS4",
        "colab_type": "text"
      },
      "source": [
        "## Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnP_cQLzuUTU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mount_drive(drivename):\n",
        "    from google.colab import drive\n",
        "    drive.mount(drivename)\n",
        "\n",
        "\n",
        "def load_csv_file(path):\n",
        "    dataframe = pd.read_csv(FILENAME)\n",
        "    if isinstance(dataframe[\"Unnamed: 0\"], pd.Series):\n",
        "        dataframe = dataframe.drop('Unnamed: 0', inplace=False, axis=1)\n",
        "    return dataframe\n",
        "\n",
        "\n",
        "def drop_features(dataframe, cols):\n",
        "    for col in cols:\n",
        "        dataframe.drop(col, axis=1, inplace=True)\n",
        "    return dataframe\n",
        "\n",
        "\n",
        "def rename_target(dataframe, label):\n",
        "    return dataframe.rename({label: \"target\"}, axis=1, inplace=False)\n",
        "\n",
        "\n",
        "def remap_boolean(dataframe, label):\n",
        "    return dataframe[label].replace({False:0, True:1}, inplace=False)\n",
        "\n",
        "\n",
        "def scale_feature(dataframe, label):\n",
        "    return dataframe[label].apply(lambda x: (x-dataframe[label].mean())/dataframe[label].std())\n",
        "\n",
        "\n",
        "def preprocess(dataframe, cols_to_drop, cols_to_remap, cols_scale):\n",
        "    start_time = default_timer()\n",
        "    dataframe = drop_features(dataframe, cols_to_drop)\n",
        "    dataframe = rename_target(dataframe, \"class\")\n",
        "    dataframe[cols_to_remap] = remap_boolean(dataframe, cols_to_remap)\n",
        "    dataframe[cols_scale] = scale_feature(dataframe, cols_scale)\n",
        "    end_time = default_timer()\n",
        "    print(f\"Processing completed. Elapsed time: {end_time-start_time}\")\n",
        "    return dataframe\n",
        "\n",
        "\n",
        "def split_data_into_feature_and_target(data, target_label=\"target\"):\n",
        "    \"\"\" Splits the dataframe into features and target\n",
        "    :param data: is dataframe with last column on right as target\n",
        "    \"\"\"\n",
        "    X = data.loc[:, data.columns != target_label].values\n",
        "    y = data[target_label].values\n",
        "    return X, y\n",
        "\n",
        "\n",
        "def plot_pca(X, y, list_n_pca_components):\n",
        "    \"\"\" plots a PCA plot... borrowed code that I want to touch as little as possible \"\"\"\n",
        "    from sklearn.decomposition import PCA\n",
        "    from sklearn.pipeline import Pipeline\n",
        "    from sklearn.model_selection import GridSearchCV\n",
        "    from sklearn.linear_model import SGDClassifier\n",
        "    from timeit import default_timer\n",
        "\n",
        "    logistic = SGDClassifier(loss='log', penalty='l2', early_stopping=True,\n",
        "                            max_iter=100, tol=1e-5, random_state=0)\n",
        "    pca = PCA()\n",
        "    pipe = Pipeline(steps=[('pca', pca), ('logistic', logistic)])\n",
        "\n",
        "    # Parameters of pipelines can be set using ‘__’ separated parameter names:\n",
        "    param_grid = {\n",
        "        'pca__n_components': list_n_pca_components,\n",
        "        'logistic__alpha': np.logspace(-4, 4, 5),\n",
        "    }\n",
        "\n",
        "    start_time = default_timer()\n",
        "    search = GridSearchCV(pipe, param_grid, iid=False, cv=10)\n",
        "    search.fit(X, y)\n",
        "    print(\"Best parameter (CV score=%0.3f):\" % search.best_score_)\n",
        "    print(search.best_params_)\n",
        "\n",
        "    # Plot the PCA spectrum\n",
        "    pca.fit(X)\n",
        "    end_time = default_timer()\n",
        "    print(\"Elapsed time to fit: {}s\".format(end_time - start_time))\n",
        "    fig, (ax0, ax1) = plt.subplots(nrows=2, sharex=True, figsize=(6, 6))\n",
        "    ax0.plot(pca.explained_variance_ratio_, linewidth=2)\n",
        "    ax0.set_ylabel('PCA explained variance')\n",
        "\n",
        "    ax0.axvline(search.best_estimator_.named_steps['pca'].n_components,\n",
        "                linestyle=':', label='n_components chosen')\n",
        "    ax0.legend(prop=dict(size=12))\n",
        "\n",
        "    # For each number of components, find the best classifier results\n",
        "    results = pd.DataFrame(search.cv_results_)\n",
        "    components_col = 'param_pca__n_components'\n",
        "    best_clfs = results.groupby(components_col).apply(\n",
        "        lambda g: g.nlargest(1, 'mean_test_score'))\n",
        "\n",
        "    best_clfs.plot(x=components_col, y='mean_test_score', yerr='std_test_score',\n",
        "                legend=False, ax=ax1)\n",
        "    ax1.set_ylabel('Classification accuracy (val)')\n",
        "    ax1.set_xlabel('n_components')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def extract_pc_into_df(data, n_pca_components):\n",
        "    from sklearn.linear_model import SGDClassifier\n",
        "    from sklearn.decomposition import PCA\n",
        "\n",
        "    X, y = split_data_into_feature_and_target(data)\n",
        "\n",
        "    logistic = SGDClassifier(loss='log', penalty='l2', early_stopping=True,\n",
        "                         max_iter=10000, tol=1e-5, random_state=0, alpha=0.0001)\n",
        "    \n",
        "    pca = PCA(n_components=n_pca_components)\n",
        "    principal_components = pca.fit_transform(X, y)\n",
        "\n",
        "    princ_comp_names = [f\"pc{a}\" for a in range(1, 12)]\n",
        "    dataframe = pd.DataFrame(principal_components, columns=princ_comp_names)\n",
        "    dataframe['target'] = data['target'].values\n",
        "\n",
        "    return dataframe\n",
        "\n",
        "\n",
        "def normality_of_distribution_test(feature, significance_level=0.05):\n",
        "    from scipy.stats import normaltest\n",
        "    test_normality = normaltest(feature, axis=0, nan_policy='propagate')\n",
        "    if test_normality[1]<significance_level:\n",
        "        print(\"This feature is normally distributed about the mean\")\n",
        "    else:\n",
        "        print(\"This feature is NOT normally distributed about the mean\")\n",
        "\n",
        "\n",
        "def fit_simple_model(data, model_type):\n",
        "    from timeit import default_timer\n",
        "    X, y = split_data_into_feature_and_target(data)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
        "    if model_type == \"naive bayes\":\n",
        "        from sklearn.naive_bayes import GaussianNB\n",
        "        model = GaussianNB()\n",
        "    else:\n",
        "        raise ValueError(\"Please select a valid model_type value\")\n",
        "    \n",
        "    start_time = default_timer()\n",
        "    fitted_model = model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    end_time = default_timer()\n",
        "    elapsed_time = end_time - start_time\n",
        "    print(f\"Model fitting and prediction complete.\\nElapsed Time: {elapsed_time}s\")\n",
        "    return (X_train, X_test, y_train, y_test, y_pred), fitted_model, elapsed_time\n",
        "\n",
        "\n",
        "def fit_get_predictions_with_CV(data, model_name, param_search_space):\n",
        "    \"\"\" Uses the GridSearchCV to fit specified model. \n",
        "    param_search_space must be compatible with models passed in \"\"\"\n",
        "    from timeit import default_timer\n",
        "\n",
        "    X, y = split_data_into_feature_and_target(data)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "    if model_name == \"RFC\":\n",
        "        from sklearn.ensemble import RandomForestClassifier\n",
        "        estimator = RandomForestClassifier()\n",
        "    \n",
        "    elif model_name == \"logistic regression\":\n",
        "        from sklearn.linear_model import LogisticRegression\n",
        "        estimator = LogisticRegression(class_weight=\"balanced\", verbose=0, random_state=42, \n",
        "                                       max_iter=100, solver=\"saga\", warm_start=False, n_jobs=-1, \n",
        "                                       l1_ratio=1)\n",
        "        \n",
        "    elif model_name == \"naive bayes\":\n",
        "        from sklearn.naive_bayes import GaussianNB\n",
        "        estimator = GaussianNB()\n",
        "\n",
        "    elif model_name == \"KNN\":\n",
        "        from sklearn.neighbors import KNeighborsClassifier\n",
        "        estimator = KNeighborsClassifier()\n",
        "    \n",
        "    else:\n",
        "        raise ValueError(\"Please enter a valid model_name string value\")\n",
        "\n",
        "    start_time = default_timer()\n",
        "    gscv = GridSearchCV(estimator, param_search_space, cv=10, error_score=\"raise\")\n",
        "    fitted_model = gscv.fit(X_train, y_train)\n",
        "    y_pred = gscv.predict(X_test)\n",
        "    end_time = default_timer()\n",
        "    elapsed_time = end_time - start_time\n",
        "    print(f\"Training, Validation and Testing are complete.\\nElapsed Time: {elapsed_time}s\")\n",
        "    return (X_train, X_test, y_train, y_test, y_pred), fitted_model, elapsed_time\n",
        "\n",
        "\n",
        "def conf_mat_parser(confusion_matrix):\n",
        "    \"\"\" parse a confusion matrix into its components \"\"\"\"\"\"\"\"\"\"\"\n",
        "    TN, FN, FP, TP = [i for j in confusion_matrix for i in j]\n",
        "    return TN, FN, FP, TP\n",
        "\n",
        "\n",
        "def detailed_confusion_matrix(y_test, y_pred):\n",
        "    \"\"\" prints out confusion matrix with more labeling and detail \"\"\"\n",
        "\n",
        "    TN, FP, FN, TP = conf_mat_parser(confusion_matrix(y_test, y_pred))\n",
        "    sensitivity = (TP/(TP+FN))\n",
        "    specificity = (TN/(TN+FP))\n",
        "    precision = (TP / (TP+FP))\n",
        "\n",
        "    print(\"                           *Fraudulent Cases are considered Positive Cases\")\n",
        "    print(\"============================================================================================\")\n",
        "    print(\"######################### Predicted Non-Fraudulent ### | ### Predicted Fraudulent ##########\")\n",
        "    print(\"\\n\")\n",
        "    print(f\"Actually Non-Fraudulent | TN = {TN}                   | FP = {FP}\")\n",
        "    print(\"\\n\")\n",
        "    print(f\"Actually Fraudulent     | FN = {FN}                       | TP = {TP} \")\n",
        "    print(\"\\n\")\n",
        "    print(f\"Specificity: {sensitivity}\")\n",
        "    print(f\"Sensitivity (aka. Recall): {specificity}\")\n",
        "\n",
        "\n",
        "def report_performance_scores(model, y_test, y_pred, train_time):\n",
        "    \"\"\" prints out some of the useful performance metrics of our model as well as returns a dataframe containing those metrics \"\"\"\n",
        "    from sklearn.metrics import (classification_report, confusion_matrix, \n",
        "                                 recall_score, precision_score, roc_auc_score,\n",
        "                                 accuracy_score, r2_score, f1_score\n",
        "                                 )\n",
        "    dataframe = pd.DataFrame({\"id\":[\"000\"], \n",
        "        \"best_parameters\":f\"{model.get_params}\", \n",
        "        \"accuracy\":[accuracy_score(y_test, y_pred)], \n",
        "        \"precision\":[precision_score(y_test, y_pred)], \n",
        "        \"recall\":[recall_score(y_test, y_pred)], \n",
        "        \"roc_auc\":[roc_auc_score(y_test, y_pred)], \n",
        "        \"r2_score\":[r2_score(y_test, y_pred)],\n",
        "        \"f1-score\": [f1_score(y_test, y_pred)],\n",
        "        \"train_time(s)\":f\"{train_time}\"\n",
        "        })\n",
        "    \n",
        "    pp.pprint(classification_report(y_test, y_pred))\n",
        "    print(\"\\n\")\n",
        "    print(f\"ROC Score: {roc_auc_score(y_test, y_pred)}\")\n",
        "    print(\"\\n\")\n",
        "    detailed_confusion_matrix(y_test, y_pred)\n",
        "    return dataframe\n",
        "\n",
        "\n",
        "def perform_mannwhitneyutest(training_anomaly_scores, test_anomaly_scores, significance_level=0.05):\n",
        "    \"\"\" non-parametric version of the t-test for checking if the means betwen two different populations are significantly different \"\"\"\n",
        "    from scipy.stats import mannwhitneyu \n",
        "    result = mannwhitneyu(test_anomaly_scores, training_anomaly_scores)\n",
        "    if result[1] < significance_level:\n",
        "        print(\"We reject the null hypothesis and conclude that the mean measurements between the two groups are statistically significantly different.\")\n",
        "    else:\n",
        "        print(\"We faile reject the null hypothesis and conclude that the mean measurements between the two groups are statistically NOT significantly different.\")\n",
        "\n",
        "\n",
        "def get_max_probas(y_pred_probs):\n",
        "    \"\"\" get array of target probabilities and return an array of \n",
        "    prediicted max probabilities for a binary class problem \"\"\"\n",
        "    df = pd.DataFrame(y_pred_probs)\n",
        "    df['max'] = df.max(axis=1)\n",
        "    y_pred_probs_max = df['max'].values\n",
        "    return y_pred_probs_max\n",
        "\n",
        "\n",
        "def predict_max_prob(model, X_test):\n",
        "    y_pred_probs = model.predict_proba(X_test)\n",
        "    y_pred_probs_max = get_max_probas(y_pred_probs)\n",
        "    return y_pred_probs_max\n",
        "\n",
        "\n",
        "def plot_roc(y_test, y_pred_probs, n_classes=2):\n",
        "    \"\"\" make sure that y_pred are probabilities \"\"\"\n",
        "    from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "\n",
        "    fpr = dict()\n",
        "    tpr = dict()\n",
        "    roc_auc = dict()\n",
        "    for i in range(n_classes):\n",
        "        fpr[i], tpr[i], _ = roc_curve(y_test, y_pred_probs)\n",
        "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "    # Compute micro-average ROC curve and ROC area\n",
        "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_pred_probs.ravel())\n",
        "    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
        "\n",
        "    plt.figure()\n",
        "    lw = 2\n",
        "    plt.plot(fpr[0], tpr[0], color='darkorange',\n",
        "            lw=lw, label='ROC curve (area = %0.2f)' % roc_auc[0])\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver Operator Characteristic Curve')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_prc(y_test, y_pred_probs, y_pred):\n",
        "    \n",
        "    average_precision = average_precision_score(y_test, y_pred)\n",
        "    precision, recall, _ = precision_recall_curve(y_test, y_pred_probs)\n",
        "\n",
        "    # In matplotlib < 1.5, plt.fill_between does not have a 'step' argument\n",
        "    step_kwargs = ({'step': 'post'}\n",
        "                if 'step' in signature(plt.fill_between).parameters\n",
        "                else {})\n",
        "    plt.step(recall, precision, color='b', alpha=0.2,\n",
        "            where='post')\n",
        "    plt.fill_between(recall, precision, alpha=0.2, color='b', **step_kwargs)\n",
        "\n",
        "    plt.xlabel('Recall')\n",
        "    plt.ylabel('Precision')\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.title('2-class Precision-Recall curve: AP={0:0.2f}'.format(\n",
        "            average_precision))\n",
        "    \n",
        "\n",
        "def sample_for_test_set(dataframe, target=\"target\", fraction=0.3, include_minority=True):\n",
        "    \"\"\" resample dataframe \"\"\"\n",
        "    if include_minority:\n",
        "        test_samples_all_nonfraud_df = pd.DataFrame(dataframe.sample(frac=0.3, replace=False), columns=dataframe.columns).reset_index()                         \n",
        "        X_test = test_samples_all_nonfraud_df.iloc[:, 1:-1].values # if \"index\" is the first column\n",
        "        y_test = test_samples_all_nonfraud_df.loc[:, target].values\n",
        "\n",
        "    else:\n",
        "        test_samples_all_nonfraud_df = pd.DataFrame(dataframe.loc[dataframe[target] == 0, :].sample(frac=0.3, replace=False), \n",
        "                                                columns=dataframe.columns).reset_index()\n",
        "        X_test = test_samples_all_nonfraud_df.iloc[:, 1:-1].values # if \"index\" is the first column\n",
        "        y_test = test_samples_all_nonfraud_df.loc[:, target].values\n",
        "\n",
        "    return X_test, y_test\n",
        "\n",
        "\n",
        "def  get_outlier_scores(X_train, X_test):\n",
        "    \"\"\" returns outlier test scores for anomalous data points \"\"\"\n",
        "    from pyod.models.knn import KNN\n",
        "    clf = KNN()\n",
        "    clf.fit(X_train)\n",
        "\n",
        "    # get outlier scores\n",
        "    y_train_scores = clf.decision_scores_  # raw outlier scores\n",
        "    y_test_scores = clf.decision_function(X_test)  # outlier scores\n",
        "\n",
        "    return y_test_scores, y_train_scores "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8nGKK0k09wRB",
        "colab_type": "text"
      },
      "source": [
        "## Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKBv-EDXcHHy",
        "colab_type": "code",
        "outputId": "a2bfc08b-eb88-44fd-b86c-de9f85c851e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "mount_drive(DRIVENAME)\n",
        "df = load_csv_file(FILENAME)\n",
        "df.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>v1</th>\n",
              "      <th>v2</th>\n",
              "      <th>v3</th>\n",
              "      <th>v4</th>\n",
              "      <th>v5</th>\n",
              "      <th>v6</th>\n",
              "      <th>v7</th>\n",
              "      <th>v8</th>\n",
              "      <th>v9</th>\n",
              "      <th>v10</th>\n",
              "      <th>v11</th>\n",
              "      <th>v12</th>\n",
              "      <th>v13</th>\n",
              "      <th>v14</th>\n",
              "      <th>v15</th>\n",
              "      <th>v16</th>\n",
              "      <th>v17</th>\n",
              "      <th>v18</th>\n",
              "      <th>v19</th>\n",
              "      <th>v20</th>\n",
              "      <th>v21</th>\n",
              "      <th>v22</th>\n",
              "      <th>v23</th>\n",
              "      <th>v24</th>\n",
              "      <th>v25</th>\n",
              "      <th>v26</th>\n",
              "      <th>v27</th>\n",
              "      <th>v28</th>\n",
              "      <th>amount</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1.359807</td>\n",
              "      <td>-0.072781</td>\n",
              "      <td>2.536347</td>\n",
              "      <td>1.378155</td>\n",
              "      <td>-0.338321</td>\n",
              "      <td>0.462388</td>\n",
              "      <td>0.239599</td>\n",
              "      <td>0.098698</td>\n",
              "      <td>0.363787</td>\n",
              "      <td>0.090794</td>\n",
              "      <td>-0.551600</td>\n",
              "      <td>-0.617801</td>\n",
              "      <td>-0.991390</td>\n",
              "      <td>-0.311169</td>\n",
              "      <td>1.468177</td>\n",
              "      <td>-0.470401</td>\n",
              "      <td>0.207971</td>\n",
              "      <td>0.025791</td>\n",
              "      <td>0.403993</td>\n",
              "      <td>0.251412</td>\n",
              "      <td>-0.018307</td>\n",
              "      <td>0.277838</td>\n",
              "      <td>-0.110474</td>\n",
              "      <td>0.066928</td>\n",
              "      <td>0.128539</td>\n",
              "      <td>-0.189115</td>\n",
              "      <td>0.133558</td>\n",
              "      <td>-0.021053</td>\n",
              "      <td>0.244964</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.191857</td>\n",
              "      <td>0.266151</td>\n",
              "      <td>0.166480</td>\n",
              "      <td>0.448154</td>\n",
              "      <td>0.060018</td>\n",
              "      <td>-0.082361</td>\n",
              "      <td>-0.078803</td>\n",
              "      <td>0.085102</td>\n",
              "      <td>-0.255425</td>\n",
              "      <td>-0.166974</td>\n",
              "      <td>1.612727</td>\n",
              "      <td>1.065235</td>\n",
              "      <td>0.489095</td>\n",
              "      <td>-0.143772</td>\n",
              "      <td>0.635558</td>\n",
              "      <td>0.463917</td>\n",
              "      <td>-0.114805</td>\n",
              "      <td>-0.183361</td>\n",
              "      <td>-0.145783</td>\n",
              "      <td>-0.069083</td>\n",
              "      <td>-0.225775</td>\n",
              "      <td>-0.638672</td>\n",
              "      <td>0.101288</td>\n",
              "      <td>-0.339846</td>\n",
              "      <td>0.167170</td>\n",
              "      <td>0.125895</td>\n",
              "      <td>-0.008983</td>\n",
              "      <td>0.014724</td>\n",
              "      <td>-0.342474</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-1.358354</td>\n",
              "      <td>-1.340163</td>\n",
              "      <td>1.773209</td>\n",
              "      <td>0.379780</td>\n",
              "      <td>-0.503198</td>\n",
              "      <td>1.800499</td>\n",
              "      <td>0.791461</td>\n",
              "      <td>0.247676</td>\n",
              "      <td>-1.514654</td>\n",
              "      <td>0.207643</td>\n",
              "      <td>0.624501</td>\n",
              "      <td>0.066084</td>\n",
              "      <td>0.717293</td>\n",
              "      <td>-0.165946</td>\n",
              "      <td>2.345865</td>\n",
              "      <td>-2.890083</td>\n",
              "      <td>1.109969</td>\n",
              "      <td>-0.121359</td>\n",
              "      <td>-2.261857</td>\n",
              "      <td>0.524980</td>\n",
              "      <td>0.247998</td>\n",
              "      <td>0.771679</td>\n",
              "      <td>0.909412</td>\n",
              "      <td>-0.689281</td>\n",
              "      <td>-0.327642</td>\n",
              "      <td>-0.139097</td>\n",
              "      <td>-0.055353</td>\n",
              "      <td>-0.059752</td>\n",
              "      <td>1.160684</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.966272</td>\n",
              "      <td>-0.185226</td>\n",
              "      <td>1.792993</td>\n",
              "      <td>-0.863291</td>\n",
              "      <td>-0.010309</td>\n",
              "      <td>1.247203</td>\n",
              "      <td>0.237609</td>\n",
              "      <td>0.377436</td>\n",
              "      <td>-1.387024</td>\n",
              "      <td>-0.054952</td>\n",
              "      <td>-0.226487</td>\n",
              "      <td>0.178228</td>\n",
              "      <td>0.507757</td>\n",
              "      <td>-0.287924</td>\n",
              "      <td>-0.631418</td>\n",
              "      <td>-1.059647</td>\n",
              "      <td>-0.684093</td>\n",
              "      <td>1.965775</td>\n",
              "      <td>-1.232622</td>\n",
              "      <td>-0.208038</td>\n",
              "      <td>-0.108300</td>\n",
              "      <td>0.005274</td>\n",
              "      <td>-0.190321</td>\n",
              "      <td>-1.175575</td>\n",
              "      <td>0.647376</td>\n",
              "      <td>-0.221929</td>\n",
              "      <td>0.062723</td>\n",
              "      <td>0.061458</td>\n",
              "      <td>0.140534</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-1.158233</td>\n",
              "      <td>0.877737</td>\n",
              "      <td>1.548718</td>\n",
              "      <td>0.403034</td>\n",
              "      <td>-0.407193</td>\n",
              "      <td>0.095921</td>\n",
              "      <td>0.592941</td>\n",
              "      <td>-0.270533</td>\n",
              "      <td>0.817739</td>\n",
              "      <td>0.753074</td>\n",
              "      <td>-0.822843</td>\n",
              "      <td>0.538196</td>\n",
              "      <td>1.345852</td>\n",
              "      <td>-1.119670</td>\n",
              "      <td>0.175121</td>\n",
              "      <td>-0.451449</td>\n",
              "      <td>-0.237033</td>\n",
              "      <td>-0.038195</td>\n",
              "      <td>0.803487</td>\n",
              "      <td>0.408542</td>\n",
              "      <td>-0.009431</td>\n",
              "      <td>0.798278</td>\n",
              "      <td>-0.137458</td>\n",
              "      <td>0.141267</td>\n",
              "      <td>-0.206010</td>\n",
              "      <td>0.502292</td>\n",
              "      <td>0.219422</td>\n",
              "      <td>0.215153</td>\n",
              "      <td>-0.073403</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         v1        v2        v3        v4  ...       v27       v28    amount  target\n",
              "0 -1.359807 -0.072781  2.536347  1.378155  ...  0.133558 -0.021053  0.244964       0\n",
              "1  1.191857  0.266151  0.166480  0.448154  ... -0.008983  0.014724 -0.342474       0\n",
              "2 -1.358354 -1.340163  1.773209  0.379780  ... -0.055353 -0.059752  1.160684       0\n",
              "3 -0.966272 -0.185226  1.792993 -0.863291  ...  0.062723  0.061458  0.140534       0\n",
              "4 -1.158233  0.877737  1.548718  0.403034  ...  0.219422  0.215153 -0.073403       0\n",
              "\n",
              "[5 rows x 30 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BA5tqekq9wvz",
        "colab_type": "text"
      },
      "source": [
        "## Dataset Profiling and Preliminary EDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dS95AYBcUzz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# report = pandas_profiling.ProfileReport(df)\n",
        "# report"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kBEBOsUuqHRS",
        "colab_type": "text"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJhhKLyOAr7t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# FILENAME = \"/content/drive/My Drive/problem_set_challenges_for_job_postings/cc.csv\"\n",
        "# df = preprocess(dataframe=df, cols_to_drop=[\"column_a\", \"time\"], cols_to_remap=\"target\", cols_scale=\"amount\" )\n",
        "# df.to_csv(\"scaled_and_processed_cc.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8U4fM-f71n9y",
        "colab_type": "text"
      },
      "source": [
        "## More EDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dscc20_t96HT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig, ax = plt.subplots(figsize=(10, 10))\n",
        "plt.xlim(df['amount'].min(), df['amount'].std()*4)\n",
        "sns.distplot(df['amount'])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLnO6GtfBj6H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig, ax = plt.subplots(figsize=(15, 15))\n",
        "corr = df.corr()\n",
        "sns.heatmap(corr, annot=False)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xyM2tjwCSuR",
        "colab_type": "text"
      },
      "source": [
        "It's hard to tell what I am looking at from this heatmap, save for the fact that the amount of money withdrawn and the target have a higher degree correlation between the first 10-ish features. \n",
        "\n",
        "Feature 2 is significantly negatively correlated to the amount of money draw. We don't have the feature names, but we can probably deduce that Feature 2 might represent a deposit into the account."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ec-zC01EGjG",
        "colab_type": "text"
      },
      "source": [
        "Is feature 2 normaly distributed? Lets plot and do statistical checks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7of-KyuDpOw",
        "colab_type": "code",
        "outputId": "bd894715-922e-4490-82ae-33368f36bb00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "fig, ax = plt.subplots(figsize=(10, 10))\n",
        "plt.xlim(df.v2.std()*-4, df.v2.std()*4)\n",
        "sns.distplot(df.v2)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f65eb8df748>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkc9aiuGpvF2",
        "colab_type": "text"
      },
      "source": [
        "### Test for normality of distribution\n",
        "\n",
        "V2 is a feature of particular interest after what we see from the heatmap. Let's test the normality of its distribution to see what ideas we can have about this particular feature."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JpYdq4LLENLr",
        "colab_type": "code",
        "outputId": "217cf96d-d473-44a8-b9a2-c1419222f48d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "normality_of_distribution_test(df.v2)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This feature is normally distributed about the mean\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzBSuF5O_0aG",
        "colab_type": "text"
      },
      "source": [
        "## Split Data into Features and Target"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfYJ2sMc_8CI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X, y = split_data_into_feature_and_target(df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ntYZmIu8NVoN",
        "colab_type": "text"
      },
      "source": [
        "## Dimensionality Reduction/Feature Extraction with PCA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Ttwiy3lNyN6",
        "colab_type": "code",
        "outputId": "8ded890b-44b6-478f-e9c8-37c1414b0022",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "plot_pca(X, y, [9])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best parameter (CV score=0.999):\n",
            "{'logistic__alpha': 0.0001, 'pca__n_components': 9}\n",
            "Elapsed time to fit: 111.49731716500003s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VyZoCUMWZCTc",
        "colab_type": "code",
        "outputId": "7c907c0d-d1ca-42fc-c637-3e64781c51e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "principalDf = extract_pc_into_df(df, n_pca_components=11)\n",
        "principalDf.head()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pc1</th>\n",
              "      <th>pc2</th>\n",
              "      <th>pc3</th>\n",
              "      <th>pc4</th>\n",
              "      <th>pc5</th>\n",
              "      <th>pc6</th>\n",
              "      <th>pc7</th>\n",
              "      <th>pc8</th>\n",
              "      <th>pc9</th>\n",
              "      <th>pc10</th>\n",
              "      <th>pc11</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.322332</td>\n",
              "      <td>-0.389117</td>\n",
              "      <td>-2.210660</td>\n",
              "      <td>1.726562</td>\n",
              "      <td>-0.839472</td>\n",
              "      <td>0.369528</td>\n",
              "      <td>0.067989</td>\n",
              "      <td>-0.140152</td>\n",
              "      <td>0.379765</td>\n",
              "      <td>-0.048637</td>\n",
              "      <td>-0.549493</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1.269691</td>\n",
              "      <td>-0.079025</td>\n",
              "      <td>-0.070287</td>\n",
              "      <td>0.245597</td>\n",
              "      <td>-0.403616</td>\n",
              "      <td>-0.066219</td>\n",
              "      <td>-0.028120</td>\n",
              "      <td>-0.065613</td>\n",
              "      <td>-0.275168</td>\n",
              "      <td>0.132686</td>\n",
              "      <td>1.601334</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.834504</td>\n",
              "      <td>1.341409</td>\n",
              "      <td>-1.644263</td>\n",
              "      <td>1.415720</td>\n",
              "      <td>0.199945</td>\n",
              "      <td>1.618960</td>\n",
              "      <td>0.189125</td>\n",
              "      <td>-0.378921</td>\n",
              "      <td>-1.401024</td>\n",
              "      <td>-0.501664</td>\n",
              "      <td>0.635762</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.947094</td>\n",
              "      <td>-0.208125</td>\n",
              "      <td>-1.669605</td>\n",
              "      <td>0.412559</td>\n",
              "      <td>1.020169</td>\n",
              "      <td>1.280021</td>\n",
              "      <td>0.020353</td>\n",
              "      <td>-0.403549</td>\n",
              "      <td>-1.348597</td>\n",
              "      <td>-0.165941</td>\n",
              "      <td>-0.206219</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.936984</td>\n",
              "      <td>-1.140952</td>\n",
              "      <td>-1.091564</td>\n",
              "      <td>1.232160</td>\n",
              "      <td>0.027633</td>\n",
              "      <td>0.098863</td>\n",
              "      <td>0.508372</td>\n",
              "      <td>0.175703</td>\n",
              "      <td>0.927640</td>\n",
              "      <td>-0.652677</td>\n",
              "      <td>-0.835605</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        pc1       pc2       pc3       pc4  ...       pc9      pc10      pc11  target\n",
              "0  1.322332 -0.389117 -2.210660  1.726562  ...  0.379765 -0.048637 -0.549493       0\n",
              "1 -1.269691 -0.079025 -0.070287  0.245597  ... -0.275168  0.132686  1.601334       0\n",
              "2  1.834504  1.341409 -1.644263  1.415720  ... -1.401024 -0.501664  0.635762       0\n",
              "3  0.947094 -0.208125 -1.669605  0.412559  ... -1.348597 -0.165941 -0.206219       0\n",
              "4  0.936984 -1.140952 -1.091564  1.232160  ...  0.927640 -0.652677 -0.835605       0\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1w_TPEo3Q7rt",
        "colab_type": "text"
      },
      "source": [
        "## Novelty Detection\n",
        "Given the extremely imbalanced class distribution in the data set, a novelty detection or anomaly detection problem can be framed and appropriate methods can be used in lieu of a classification problem. \n",
        "\n",
        "Therefore, the traditional use of the train_test_split module is probably inappropriate in this case and specifically training on \n",
        "\n",
        "Train the data on only nominal cases (with one anomalous case, just so the model doesnt break) and then test on anomalous cases to see how well we do in an semi-supervised learning approach"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krAkOejx_QIK",
        "colab_type": "text"
      },
      "source": [
        "### An Example of incorrect partitioning with train_test split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJe7xKs09SDA",
        "colab_type": "code",
        "outputId": "b05eeda3-03d4-4070-8b02-401777333fef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "from pyod.models.lof import LOF\n",
        "from pyod.models.pca import PCA\n",
        "from pyod.models.iforest import IForest\n",
        "X, y = split_data_into_feature_and_target(principalDf)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
        "\n",
        "model = IForest(contamination=(sum(y_train)/y_train.shape[0]), \n",
        "                n_estimators=100, max_samples='auto', max_features=1.0, \n",
        "                bootstrap=False, n_jobs=1, behaviour='old', \n",
        "                random_state=None, verbose=0)\n",
        "\n",
        "model.fit(X=X_train, y=y_train)\n",
        "test_anomaly_scores = model.decision_function(X_test)\n",
        "training_anomaly_scores = model.decision_scores_\n",
        "y_pred = model.fit_predict(X_test)\n",
        "y_pred_probs = model.predict_proba(X_test)\n",
        "\n",
        "score = model.fit_predict_score(X_train, y_train, scoring='roc_auc_score')\n",
        "print(score)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "roc_auc_score: 0.9233402576035754\n",
            "0.9233402576035754\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsxUIOgp9bib",
        "colab_type": "code",
        "outputId": "e03270ce-1164-4484-b442-667b8545fed9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "plt.xlim(training_anomaly_scores.min(), training_anomaly_scores.std()*2)\n",
        "sns.distplot(training_anomaly_scores)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f65e8b2d940>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfHGLw-L9us2",
        "colab_type": "code",
        "outputId": "839652e3-f2bd-4dc8-92ce-7303bc3d4710",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        }
      },
      "source": [
        "print(pd.Series(training_anomaly_scores).describe())\n",
        "print(np.median(training_anomaly_scores))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "count    170884.000000\n",
            "mean         -0.091648\n",
            "std           0.054960\n",
            "min          -0.156476\n",
            "25%          -0.128576\n",
            "50%          -0.108496\n",
            "75%          -0.071260\n",
            "max           0.295578\n",
            "dtype: float64\n",
            "-0.10849573993603029\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cCOeNp79UrS",
        "colab_type": "code",
        "outputId": "6c2e4a85-21f7-4b51-c63a-021f8d756157",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "plt.xlim(test_anomaly_scores.min(), test_anomaly_scores.std()*2)\n",
        "sns.distplot(test_anomaly_scores)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f65e8b2d940>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L401PVJi-ZbY",
        "colab_type": "code",
        "outputId": "b55d8b1d-1f0c-4b14-b4d4-311e3229aaee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        }
      },
      "source": [
        "print(pd.Series(test_anomaly_scores).describe())\n",
        "print(np.median(test_anomaly_scores))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "count    113923.000000\n",
            "mean         -0.091527\n",
            "std           0.055091\n",
            "min          -0.155938\n",
            "25%          -0.128445\n",
            "50%          -0.108472\n",
            "75%          -0.071135\n",
            "max           0.298274\n",
            "dtype: float64\n",
            "-0.10847210794413825\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGpKVJWI9fMi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_roc(y_test, get_max_probas(y_pred_probs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8qVzaUt9l5j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_prc(y_test, get_max_probas(y_pred), y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7WtuyUoU_6Ie",
        "colab_type": "text"
      },
      "source": [
        "## Conclusion of Train_test_split for Outlier/Anomaly/Novelty Dection\n",
        "\n",
        "We see that the decision function has not learned from enough fradulent samples due this random sample partitioning method. A more heuristic approach should be pursued when approaching an anomaly detection/novelty detection problem."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FGeCWTMC7wl",
        "colab_type": "text"
      },
      "source": [
        "## More appropriate selection of dataset partitioning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFaxOzFxQ7DW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_data = principalDf.loc[principalDf[\"target\"] == 0, :]\n",
        "training_data = training_data.append(principalDf.iloc[6329, :])\n",
        "X_train = training_data.iloc[:, :-1].values\n",
        "y_train = training_data.iloc[:, -1].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khtrm2GIUeox",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_data = principalDf.loc[principalDf.target==1, :]\n",
        "X_test = test_data.iloc[:, :-1].values\n",
        "y_test = test_data.iloc[:, -1].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9Al4xlKVagH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = IForest(contamination=(sum(y_train)/y_train.shape[0]), n_estimators=100, max_samples='auto', \n",
        "                max_features=1.0, bootstrap=False, n_jobs=1, behaviour='old', random_state=None, verbose=0)\n",
        "\n",
        "model.fit(X=X_train, y=y_train)\n",
        "test_anomaly_scores = model.decision_function(X_test)\n",
        "training_anomaly_scores = model.decision_scores_\n",
        "y_pred = model.fit_predict(X_test)\n",
        "y_pred_probs = model.predict_proba(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8roIrFqzvtJ4",
        "colab_type": "code",
        "outputId": "06cb15ce-c334-4aa9-f893-bbcca5bb9554",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "score = model.fit_predict_score(X_train, y_train, scoring='roc_auc_score')\n",
        "score"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "roc_auc_score: 0.9820445632485096\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9820445632485096"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxrnhNJQkRgd",
        "colab_type": "code",
        "outputId": "cb1b3b5d-f077-438b-9d15-d4c0efe079bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "fig, ax = plt.subplots(figsize=(10, 10))\n",
        "plt.xlim(min(training_anomaly_scores), training_anomaly_scores.std()*6)\n",
        "sns.distplot(training_anomaly_scores)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f65e2e1a668>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssE9nJCNmk5W",
        "colab_type": "code",
        "outputId": "377d0269-14b6-4fe7-9734-620299f330e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        }
      },
      "source": [
        "pd.Series(training_anomaly_scores).describe()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    284316.000000\n",
              "mean         -0.089673\n",
              "std           0.054187\n",
              "min          -0.154594\n",
              "25%          -0.126583\n",
              "50%          -0.105174\n",
              "75%          -0.069850\n",
              "max           0.288611\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXqAgv8Yna57",
        "colab_type": "code",
        "outputId": "aa416287-a029-421c-d9fe-f37312b68441",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.median(training_anomaly_scores)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.10517410235439209"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YE9tXMPOkX-o",
        "colab_type": "code",
        "outputId": "081248e4-cf88-49eb-d766-662f8def30e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "fig, ax = plt.subplots(figsize=(10, 10))\n",
        "sns.distplot(test_anomaly_scores)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f65e2d08898>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZmCYZkwD9wL",
        "colab_type": "text"
      },
      "source": [
        "Comment: there is a clear flip in the distribution in the distribution of anomaly values produced by the Isolation forest when comparing the fradulent cases vs the nominal cases. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jS8OLuX7meaB",
        "colab_type": "code",
        "outputId": "d940054b-915a-4ac8-f90d-35dfd0d54657",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        }
      },
      "source": [
        "pd.Series(test_anomaly_scores).describe()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    492.000000\n",
              "mean       0.103832\n",
              "std        0.103491\n",
              "min       -0.145564\n",
              "25%        0.042235\n",
              "50%        0.108970\n",
              "75%        0.189742\n",
              "max        0.261741\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IrWKiSasnTro",
        "colab_type": "code",
        "outputId": "943c0e35-7712-420e-e6b8-dc7bdaecf6d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.median(test_anomaly_scores)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.10897037851418123"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocukpAymmMAK",
        "colab_type": "code",
        "outputId": "134e04b1-1b3b-44ee-d099-7520412fd80f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "perform_mannwhitneyutest(training_anomaly_scores, test_anomaly_scores)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "We reject the null hypothesis and conclude that the mean measurements between the two groups are statistically significantly different.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57gxeaSszHWh",
        "colab_type": "code",
        "outputId": "fe7a969e-f59f-42a0-f48e-c7aa2451c74a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "eff = pd.DataFrame(np.c_[y_test, y_pred], columns=[\"real value\", \"predicted value\"])\n",
        "eff[\"predicted value\"].value_counts()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    491\n",
              "1      1\n",
              "Name: predicted value, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZVILLnOhrWC",
        "colab_type": "code",
        "outputId": "b339fb81-863d-4d6c-ac40-c8b2383167bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        }
      },
      "source": [
        "%matplotlib inline\n",
        "plot_roc(y_test, get_max_probas(y_pred_probs))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nafp/JToCaYSPdnMAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1PrhP5CHGty",
        "colab_type": "text"
      },
      "source": [
        "This probably occured because I only included 1 fraudulent case in the training dataset..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mx3C_n1SkG1o",
        "colab_type": "code",
        "outputId": "cb83cffe-da1d-46cd-d8f8-944dc8cf075f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        }
      },
      "source": [
        "plot_prc(y_test, get_max_probas(y_pred_probs), y_pred)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nfwH64H0TtJuMwAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xdqg4Z0PHQG4",
        "colab_type": "text"
      },
      "source": [
        "Same as above."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Bj4bp5DlVPR",
        "colab_type": "text"
      },
      "source": [
        "## Conclusion on Using PCA for Unsupervised Novelty Detection\n",
        "\n",
        "What's interesting here is that the anomaly scores for the training set (essentially all nominal cases) include max values much higher if not double that of the test set (all anomalous cases). The assumptions in the observations however are true - that he anomaly scores of the fraud cases in the test set are on average 5-fold higher than that of the training/nominal cases (mean, median, mode, standard deviation). This was also varified with the Mann-Whitney U test."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Vyv6QSyC-az",
        "colab_type": "text"
      },
      "source": [
        "## Addressing Class Imbalance - Down Sampling Majority Class\n",
        "\n",
        "Another approach to addressing the problem of class imbalance is with down-sampling the majority class. This is something we've done before in a few other problems, and it might not be an option in all the cases. In this case, however, I think we have enough data points in total, and enough cases of the majority class we can down sample from. \n",
        "\n",
        "Keep in mind, we want to downsample to include the most influential and representative samples to learn from from the majority negative class. We will be making use of the SMOTE python library and its methods to select an approprirate down-sampling strategy for our problem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G04s5TKAzOln",
        "colab_type": "text"
      },
      "source": [
        "### Under Sampling of the Majority Class Naively\n",
        "\n",
        "This approach reducees the number of majority cases in the dataset to help the decision function learn less about the signals from the majority case and more from that of the minority case. \n",
        "\n",
        "Depending on how many minority cases you actually have, this might be a terrible idea, in the most extreme of cases, but we will never know unless we learn and try."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zy4xcLzGzSXV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "rus = RandomUnderSampler(random_state=0, replacement=True)\n",
        "X_resampled, y_resampled = rus.fit_resample(X, y)\n",
        "print(sorted(Counter(y_resampled).items()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XicoWO5B3rnv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "KMUS_df = pd.DataFrame(np.c_[X_resampled, y_resampled], columns=principalDf.columns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9cm42qc3eVQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "param_grid = {\n",
        "    \"n_neighbors\":[3, 4, 5]\n",
        "}\n",
        "\n",
        "knn_data_bundle, fitted_model, elapsed_time = fit_get_predictions_with_CV(KMUS_df, \"KNN\", param_grid)\n",
        "\n",
        "y_pred = knn_data_bundle[4]\n",
        "y_test = knn_data_bundle[3]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFca12TW3iyt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fitted_model.best_params_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkErp4eF3edo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "report_df = report_performance_scores(fitted_model, y_test, y_pred, elapsed_time)\n",
        "report_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3D5_YGA2kSrO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.3, random_state=42)\n",
        "y_pred_probs = fitted_model.predict_proba(X_test)\n",
        "y_pred_probs_max = get_max_probas(y_pred_probs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4sjFjww3ekS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_roc(y_test, get_max_probs(y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kES7HV3z8RRn",
        "colab_type": "text"
      },
      "source": [
        "When we plot the probabilities on the ROC curbe, we get a crappy model. When we plot the class predictions themselves, we get something that looks more awesome but incorrect.\n",
        "\n",
        "We can test this model against randomly sampled non-fraud cases and see how well this model performs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "27FDKrCnS-ZQ",
        "colab": {}
      },
      "source": [
        "# only non-fraudulent cases for this test\n",
        "X_test, y_test = sample_for_test_set(principalDf, include_minority=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9hEUHn4CS-ZX",
        "colab": {}
      },
      "source": [
        "y_pred = fitted_model.predict(X_test)\n",
        "y_pred_probs = fitted_model.predict_proba(X_test)\n",
        "y_pred_probs_max = get_max_probas(y_pred_probs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6Sp5-lAIS-Za",
        "colab": {}
      },
      "source": [
        "y_pred = pd.Series(y_pred)\n",
        "y_pred.value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-DNpHOjLTSrA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "detailed_confusion_matrix(y_test, y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CrZpVZmZoHLQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_roc(y_test, y_pred_probs_max)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqVoQWcPVc-l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(f\"{1753/(1753+83541)} %\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqUhr1wbVCKS",
        "colab_type": "text"
      },
      "source": [
        "There were no fraudulent cases in this step, however, there alarm in the model went off in the cases of 1753 cases, with this type of naive sampling in this instance. This model therefore would cause unncessary harm and arm in its clients 2% of the time, which is too shockingly high of a number. This needs to be lowered because the harm and alarm of false positive cases can be enough for your clients to end their relationship with you."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uWKh_DpfS-Zc",
        "colab": {}
      },
      "source": [
        "plot_roc(y_test, y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_2bVffTAQSq",
        "colab_type": "text"
      },
      "source": [
        "### Undersampling of majority class with a meta-estimator\n",
        "\n",
        "With an instance hardness threshold approach, we can use a meta-estimator in the form of a logistic regressor, to filter out noisy examples that do not reach a probability threshold for inclusion in the dataset. This method employs cross validation as well"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tuUnhzbAUYs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from imblearn.under_sampling import InstanceHardnessThreshold\n",
        "from collections import Counter\n",
        "iht = InstanceHardnessThreshold(random_state=0,\n",
        "                                estimator=LogisticRegression(\n",
        "                                    solver='lbfgs', multi_class='auto'))\n",
        "X_resampled, y_resampled = iht.fit_resample(X, y)\n",
        "print(sorted(Counter(y_resampled).items()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sAs_F3wlAqVg",
        "colab": {}
      },
      "source": [
        "IHTUS_df = pd.DataFrame(np.c_[X_resampled, y_resampled], columns=principalDf.columns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "meAeZJWDAqVl",
        "colab": {}
      },
      "source": [
        "param_grid = {\n",
        "    \"n_neighbors\":[3, 4, 5]\n",
        "}\n",
        "\n",
        "knn_data_bundle, fitted_model, elapsed_time = fit_get_predictions_with_CV(IHTUS_df, \"KNN\", param_grid)\n",
        "\n",
        "y_pred = knn_data_bundle[4]\n",
        "y_test = knn_data_bundle[3]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GMWQHUw6AqVn",
        "colab": {}
      },
      "source": [
        "report_df = report_performance_scores(fitted_model, y_test, y_pred, elapsed_time)\n",
        "report_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EIDDNqLAAqVo",
        "colab": {}
      },
      "source": [
        "plot_roc(y_test, y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ucw-ZBVQA7BM",
        "colab_type": "text"
      },
      "source": [
        "As we can see, running this sampling method out of the box gives us perfect scores across the board.... WOOHOO! We don't want to be using this type of resampling method because of overfitting, if you cannot tell by the sarcasm. And even if we did, we would have to employ a much more stringent regularization mechanism.\n",
        "\n",
        "Now we generate samples to test against. Again, no fraudulent cases in this sampling."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJvaLWOQW7UM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test, y_test = sample_for_test_set(principalDf, include_minority=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6Qc4eRlXTnC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = fitted_model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUhzXJ8XXUx_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "detailed_confusion_matrix(y_test, y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMwQ6cU6X591",
        "colab_type": "text"
      },
      "source": [
        "From the examples that we have above, in general, it seems like undersampling the majority class and castrating essentially the entire dataset (70%), this decision function was not able to learn from enough non-fraud examples and pings for a lot of non-fraud cases as fraud cases. This sampling method seems to probably be the most detrimental to this model, in anycase.\n",
        "\n",
        "**VERDICT**: we do not use undersampling of the majority with a meta-estimator."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7OipSgA8wIY",
        "colab_type": "text"
      },
      "source": [
        "## Undersampling of the Majority Class with OneSidedSelection\n",
        "\n",
        "In the contrary, OneSidedSelection will use TomekLinks to remove noisy samples [KM1997]. In addition, the 1 nearest neighbor rule is applied to all samples and the one which are misclassified will be added to the set C. No iteration on the set S will take place."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UO_MQkXu9IOT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from imblearn.under_sampling import OneSidedSelection\n",
        "oss = OneSidedSelection(random_state=0)\n",
        "X_resampled, y_resampled = oss.fit_resample(X, y)\n",
        "print(sorted(Counter(y_resampled).items()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHHF_90w9I7Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "OSS_df = pd.DataFrame(np.c_[X_resampled, y_resampled], columns=principalDf.columns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Av2hTIIg9JTm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "param_grid = {\n",
        "    \"n_neighbors\":[3, 4, 5]\n",
        "}\n",
        "\n",
        "knn_data_bundle, fitted_model, elapsed_time = fit_get_predictions_with_CV(OSS_df, \"KNN\", param_grid)\n",
        "\n",
        "y_pred = knn_data_bundle[4]\n",
        "y_test = knn_data_bundle[3]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcex1k7u9K9h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "report_df = report_performance_scores(fitted_model, y_test, y_pred, elapsed_time)\n",
        "report_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JX9d_rGy9Lb0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_roc(y_test, y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CMhnoBct9MTY",
        "colab_type": "text"
      },
      "source": [
        "This method seems like a more balanced approach to undersampling the minority case. We see that we've kept the same number of majority cases somehow, but achieved much better performance with this type of sampling strategy. I've not read in depth about how the sampling strategy employed but I think it will be important to know how it is done. Something about Tomek links."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DP9r4U6lOiwO",
        "colab_type": "text"
      },
      "source": [
        "## Test Modeling against Test dataset (previous majority down sampling)\n",
        "\n",
        "Create a test data set by resampling a portion of the non-fraud cases and make that the entire test dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zs7Ip-4yxQ6y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# only non-fraudulent cases for this test\n",
        "X_test, y_test = sample_for_test_set(principalDf, include_minority=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGuPKBi7OJbE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = fitted_model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dk4BQUTfe_Pj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = pd.Series(y_pred)\n",
        "y_pred.value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iW2dBSJ2P6ar",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_roc(y_test, y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jHEES27c_TdN",
        "colab": {}
      },
      "source": [
        "# Include minority cases in the sampling\n",
        "X_test, y_test = sample_for_test_set(principalDf, fraction=0.5, include_minority=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "44gFrzbn_TdU",
        "colab": {}
      },
      "source": [
        "y_pred_probs = fitted_model.predict_proba(X_test)\n",
        "y_pred = fitted_model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2BqBjWxV_TdW",
        "colab": {}
      },
      "source": [
        "y_pred = pd.Series(y_pred)\n",
        "y_pred.value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfSz9rmm_0sr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "report = report_performance_scores(fitted_model, y_test, y_pred, elapsed_time)\n",
        "report.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1SYOTwZBgDUE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = fitted_model.predict(X_test)\n",
        "y_pred_probs = fitted_model.predict_proba(X_test)\n",
        "y_pred_probs_max = get_max_probas(y_pred_probs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MzSRU8xRhsHT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_roc(y_test, y_pred_probs_max)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1HHhv5SBmCB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "detailed_confusion_matrix(y_test, y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9YtyQCx74U3",
        "colab_type": "text"
      },
      "source": [
        "# Conclusion of Down Sampling Strategy\n",
        "\n",
        "Using the OneSideSelection down sampling strategy, fitting a model to this dataset, and then testing on a purely majority-class dataset yields positive expected values (i.e., almost 0 fraudulent cases predicted), meaning that the decision function has learned of some of the patterns for fraudulent activity.\n",
        "\n",
        "Having a higher Sensitivity score here is important because we want to capture as much of the fraudulent activity as possible, while mitigating the number of missed-detections and the number of false-alarms. In this case, there were 30 missed fraudulent cases that went under the radar and 5 false alarms for the 124 pings for frauduldent activity.\n",
        "\n",
        "This is a start but this is certainly not good enough. We need to get that False-Positive rate/Missed-Fraudulent number as low as possible."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6C6ybFg0F-F",
        "colab_type": "text"
      },
      "source": [
        "### Over sampling of the Minority Class\n",
        "\n",
        "We over sample the minority class to have more examples to learn from, but rather than just randomly doing it, there are some technicality to the approaches that we can choose. I'll go through training a decision function with resampling using two powerful methods offered by the imbalanced-learn library:\n",
        "\n",
        "1) SMOTE - Synthetic Minority Oversampling Technique\n",
        "\n",
        "2) ADASYN - Adaptive Synthetic sampling\n",
        "\n",
        "These two oversampling approaches use methods of interpolation to generate synthetic samples as opposed to the type of sampling done with Random over sampling, which duplicates examples.\n",
        "\n",
        "Formula for SMOTE sample generation:\n",
        "\n",
        "![Formula for SMOTE sample generation](https://imbalanced-learn.readthedocs.io/en/stable/_images/math/7d17f8d1d74c655eb15821661276d94c82d0e5b4.png)\n",
        "\n",
        "Lambda is a value between 0 and 1 and a sample is interpolated along the line between Xi and Xzi.\n",
        "\n",
        "<br>\n",
        "\n",
        "![Sampling](https://imbalanced-learn.readthedocs.io/en/stable/_images/sphx_glr_plot_illustration_generation_sample_0011.png)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAGhw1fM0FHq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "X_resampled, y_resampled = SMOTE().fit_resample(X, y)\n",
        "print(sorted(Counter(y_resampled).items()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vz4bVsdHJUMn",
        "colab": {}
      },
      "source": [
        "smote_df = pd.DataFrame(np.c_[X_resampled, y_resampled], columns=principalDf.columns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_jFdktwFJUMt",
        "colab": {}
      },
      "source": [
        "param_grid = {\n",
        "    \"n_neighbors\":[3, 4, 5]\n",
        "}\n",
        "\n",
        "knn_data_bundle, fitted_model, elapsed_time = fit_get_predictions_with_CV(smote_df, \"KNN\", param_grid)\n",
        "\n",
        "y_pred = knn_data_bundle[4]\n",
        "y_test = knn_data_bundle[3]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lSZL9E0MJUMw",
        "colab": {}
      },
      "source": [
        "report_df = report_performance_scores(fitted_model, y_test, y_pred, elapsed_time)\n",
        "report_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5iri_NloyRg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, train_size=0.3, random_state=42)\n",
        "y_pred_probs = fitted_model.predict_proba(X_test)\n",
        "y_pred_probs_max = get_max_probas(y_pred_probs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QcIsZCM9JUMy",
        "colab": {}
      },
      "source": [
        "plot_roc(y_test, y_pred_probs_max)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4T94pt7AI7jg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from imblearn.over_sampling import ADASYN\n",
        "\n",
        "X_resampled, y_resampled = ADASYN().fit_resample(X, y)\n",
        "print(sorted(Counter(y_resampled).items()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PCZjcsIXJVIw",
        "colab": {}
      },
      "source": [
        "adasyn_df = pd.DataFrame(np.c_[X_resampled, y_resampled], columns=principalDf.columns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Rj4xfgrPJVI1",
        "colab": {}
      },
      "source": [
        "param_grid = {\n",
        "    \"n_neighbors\":[3, 4, 5]\n",
        "}\n",
        "\n",
        "knn_data_bundle, fitted_model, elapsed_time = fit_get_predictions_with_CV(adasyn_df, \"KNN\", param_grid)\n",
        "\n",
        "y_pred = knn_data_bundle[4]\n",
        "y_test = knn_data_bundle[3]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "c7SeWTlNJVI3",
        "colab": {}
      },
      "source": [
        "report_df = report_performance_scores(fitted_model, y_test, y_pred, elapsed_time)\n",
        "report_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "r-Ui_D6iJVI4",
        "colab": {}
      },
      "source": [
        "plot_roc(y_test, y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMxiHe6ONbbN",
        "colab_type": "text"
      },
      "source": [
        "### Outlier and Novelty Detection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "admdSB6ZHpuU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install pyod"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCaH7PdeG9j8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# we can do some unsupervised learning targetted around and outlier detection"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7YSYxFbxMIu",
        "colab_type": "text"
      },
      "source": [
        "## Explainablility of the Features for the Predicted Values using LIME"
      ]
    }
  ]
}